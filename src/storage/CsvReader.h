/*
 * Copyright 2017-present varchar.io
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <fstream>
#include <iostream>

#include "SchemaHelper.h"
#include "common/Compression.h"
#include "common/Conv.h"
#include "common/Errors.h"
#include "common/Format.h"
#include "common/Hash.h"
#include "meta/TableSpec.h"
#include "storage/NFS.h"
#include "surface/DataSurface.h"

/**
 * A CSV file reader, with or without header for schema
 */
namespace nebula {
namespace storage {

// used for skipping unused rows (head + meta)
class DevNull {};
std::istream& operator>>(std::istream&, DevNull&);

class CsvRow : public nebula::surface::RowData {
public:
  CsvRow(char delimiter) : delimiter_{ delimiter } {}
  virtual ~CsvRow() = default;

  bool isNull(const std::string&) const override {
    // TODO(cao) - CSV reader doesn't produce null valus for now
    return false;
  }

#define CONV_TYPE_INDEX(TYPE, FUNC)                      \
  TYPE FUNC(const std::string& field) const override {   \
    auto index = columnLookup_(field);                   \
    auto& v = const_cast<std::string&>(data_.at(index)); \
    nebula::common::unformat<TYPE>(v);                   \
    return nebula::common::safe_to<TYPE>(v);             \
  }

  CONV_TYPE_INDEX(bool, readBool)
  CONV_TYPE_INDEX(int8_t, readByte)
  CONV_TYPE_INDEX(int16_t, readShort)
  CONV_TYPE_INDEX(int32_t, readInt)
  CONV_TYPE_INDEX(int64_t, readLong)
  CONV_TYPE_INDEX(float, readFloat)
  CONV_TYPE_INDEX(double, readDouble)
  CONV_TYPE_INDEX(int128_t, readInt128)

  std::string_view readString(const std::string& field) const override {
    auto index = columnLookup_(field);
    return data_.at(index);
  }

#undef CONV_TYPE_INDEX

  // compound types
  std::unique_ptr<nebula::surface::ListData> readList(const std::string&) const override {
    throw NException("Array not supported yet.");
  }

  std::unique_ptr<nebula::surface::MapData> readMap(const std::string&) const override {
    throw NException("Map not supported yet.");
  }

  void setData(const std::vector<std::string> data) {
    data_ = std::move(data);
  }

  void setSchema(const std::function<size_t(const std::string&)>& columnLookup) {
    columnLookup_ = columnLookup;
  }

public:
  // true if read a valid row, otherwise false
  bool readNext(std::istream&);
  inline const std::vector<std::string>& rawData() const {
    return data_;
  }

private:
  char delimiter_;
  // reference a line generated by reader
  std::vector<std::string> data_;
  std::function<size_t(std::string)> columnLookup_;
};

// declare a operator to feed in stream to a csv row
std::istream& operator>>(std::istream&, CsvRow&);

class CsvReader : public nebula::surface::RowCursor {
public:
  CsvReader(const std::string& file, const nebula::meta::CsvProps& csv, const std::vector<std::string>& columns)
    : nebula::surface::RowCursor(0), fstream_{ file }, row_{ csv.delimiter.at(0) }, cacheRow_{ csv.delimiter.at(0) } {
    // if the file is compressed, we decompress it first
    if (csv.compression == "gz") {
      LOG(INFO) << "Ungzip the csv file before reading: " << file;
      auto localFs = nebula::storage::makeFS("local");
      this->temp_ = localFs->temp();
      nebula::common::ungzip(file, this->temp_);
      this->fstream_ = std::ifstream(this->temp_);
    }

    // a few scenarios need to be handled
    // 1. schema provided
    // 1.a: csv has header - let's match column index to column name by reading header.
    // 1.b: csv has no header - let's assuming the schema is sequential columns of the csv file
    // 2. schema not provided:
    // 2.a: csv has header - we need to read headers to use them as the schema.
    // 2.b: csv has no header - fail, don't know how to process schema
    LOG(INFO) << "Reading a delimiter separated file by " << csv.delimiter;
    std::vector<std::string> names;
    const auto hasSchema = columns.size() > 0;

    // scenario 1.b: if the schema is given, has no header
    if (!csv.hasHeader) {
      // 2.b - don't know how to handle
      if (columns.size() == 0) {
        throw NException("Can't figure out schema without header");
      }

      // schema names provided
      names = columns;
    } else {
      // read the header
      N_ENSURE(row_.readNext(fstream_), "Failed to read csv header unexpectedly.");

      // extract all names
      const auto& raw = row_.rawData();
      for (size_t i = 0, size = raw.size(); i < size; ++i) {
        names.emplace_back(nebula::common::normalize(raw.at(i)));
      }

      // dedup column names
      dedup(names);
    }

    // build the name to index map
    for (size_t i = 0, size = names.size(); i < size; ++i) {
      const auto name = names.at(i);
      // notes: columns could be partial of all data and it should be already deduped
      if (!hasSchema || std::find(columns.begin(), columns.end(), name) != columns.end()) {
        columns_[name] = i;
      }
    }

    cacheRow_.setSchema([this](const std::string& name) -> size_t {
      return columns_.at(name);
    });

    // if data has header and header was not consumed yet (to build schema), we have to skip the first row
    DevNull devnull;
    // if data has meta in the second row, skip it too
    if (csv.hasMeta) {
      fstream_ >> devnull;
    }

    // read one row
    if (row_.readNext(fstream_)) {
      size_ = 1;
    }
  }

  virtual ~CsvReader() {
    if (this->temp_.size() > 0) {
      unlink(this->temp_.c_str());
    }
  }

  // next row data of CsvRow
  virtual const nebula::surface::RowData& next() override {
    // consume a row and read a new row
    cacheRow_.setData(std::move(row_.rawData()));

    // read next row
    // we should handle those to skip less rows
    while (row_.readNext(fstream_)) {
      // sometimes the data has trailing delimeter
      // and we may have one more collected than column size
      if (row_.rawData().size() >= columns_.size()) {
        size_ += 1;
        break;
      }
    }

    index_++;
    return cacheRow_;
  }

  virtual std::unique_ptr<nebula::surface::RowData> item(size_t) const override {
    throw NException("CSV Reader does not support random access by row number");
  }

private:
  std::string temp_;
  std::ifstream fstream_;
  CsvRow row_;
  CsvRow cacheRow_;
  nebula::common::unordered_map<std::string, size_t> columns_;
};

} // namespace storage
} // namespace nebula