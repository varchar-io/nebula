namespace nebula.service;

table EchoReply {
  message: string;
}

table EchoPing {
  name: string;
}

table ManyEchoPings {
  name: string;
  num_greetings: int;
}

//////////////////////////////////////////////////////////////////////////////////////////////////
// Define Query Plan Serialization Format
//////////////////////////////////////////////////////////////////////////////////////////////////

// cpp: Query - query serialization and compile in node
table QueryPlan {
  uuid: string;
  tbl: string;
  filter: string;
  fields: [string];
  groups: [uint32];
  sorts: [uint32];
  desc: bool;
  limit: uint64;
  tstart: uint64;
  tend: uint64;
}

// cpp: Flat Buffer - intermediate memory batch serde
// define serialized batch type - it can be customized binary format such as flat, json or csv.
enum BatchType: byte {
  Flat = 0, Json = 1
}
table BatchRows {
  schema: string;
  type: BatchType = Flat;
  data: [byte];
}

// an endpoint to report all blocks along with statistics
table DataBlock {
  tbl: string;
  id: uint64;
  ts: uint64;
  te: uint64;
  spec: string;
  storage: string;

  rows: uint64;
  rsize: uint64;
}

table NodeStateRequest {
  type: int;
}

table NodeStateReply {
  blocks: [DataBlock];
}

//////////////////////////////////////////////////////////////////////////////////////////////////
// Define Task Spec Serialization Format
//////////////////////////////////////////////////////////////////////////////////////////////////
table PartitionInfo {
  values: [string];
  chunk: uint64;
}

table ColumnProp {
  name: string;
  // bloom filter
  bf: bool;
  // enable dictionary
  dict: bool;
  // enable compression
  comp: bool;
  // default value when input is NULL
  dv: string;
  // partition info of this column
  pi: PartitionInfo;
}

table ColumnMap {
  name: string;
  index: uint32;
}

table Serde {
  protocol: string;

  // optional: column map - map column name to some integer value
  column_map: [ColumnMap];
}

// this is serde format mapping to IngestSpec
// we also flatten other info into the single task spec.
// TODO(cao) - do not flatten fields, it is hard to maintain
// Create a new table type to hold these table speicfic fields
table IngestTask {
  // ref: TableSpec.name
  name: string;

  // ref: TableSpec.max_hr
  max_hr: uint64;

  // ref: TableSpec.loader 
  loader: string;

  // ref: TableSpec.DataSource
  source: byte;

  // location of the table
  location: string;

  // ref: TableSpec.format 
  format: string;

  // ref: TableSpec.schema 
  schema: string;

  // ref: TimeType
  time_type: byte;

  // ref: TimeSpec.unixtimeValue
  time_value: uint64;

  // ref: TimeSpec.colName
  time_column: string;

  // ref: TimeSpec.pattern
  time_format: string;

  // data serde
  serde: Serde;

  // column properties
  column_props: [ColumnProp];

  // ingest spec itself
  version: string;
  id: string;
  domain: string;
  size: uint64;
  state: byte;
  date: uint64;
}

table Spec{
  tbl: string;
  spec: string;
}

// expire blocks 
table ExpireTask {
  // list of blocks by block ID (toString)
  specs: [Spec];
}

// fast communicate one single command specified by command value
table CommandTask {
  command: string;
}

table TaskSpec {

  // this is directly mapping to nebula::common::TaskType
  type: byte;

  // indicate executor to execute the task right away in sync or not
  sync: bool;

  // present super set fields here for each type to choose
  ingest: IngestTask;

  // present if type is expiration
  expire: ExpireTask;

  // present a command task
  command: CommandTask;
}

table TaskReply {
  // this is directly mapping to nebula::common::TaskState
  state: byte;
}

rpc_service NodeServer {
  Echo(EchoPing): EchoReply;
  Echos(ManyEchoPings): EchoReply(streaming: "server");

  // accept a query plan and send back the results
  Query(QueryPlan): BatchRows;

  // poll memory data status
  Poll(NodeStateRequest): NodeStateReply;

  // assign a task to a node - could be duplicate
  Task(TaskSpec): TaskReply;
}